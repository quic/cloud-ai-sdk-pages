# Model Architecture Support

The Cloud AI 100 family of accelerators supports a comprehensive range of model architectures and use-cases. 

- [Transformer Encoders](https://github.com/quic/cloud-ai-sdk/tree/1.12/models/language_processing/encoder) 
- [Transformer Decoders](https://github.com/quic/cloud-ai-sdk/tree/1.12/models/language_processing/decoder)
- Tranformer Encoder - Decoder (coming soon)
- [Computer vision](https://github.com/quic/cloud-ai-sdk/tree/1.12/models/vision) - CNN, R-CNN, vision transformers  
- [Diffusion](https://github.com/quic/cloud-ai-sdk/tree/1.12/models/multimodal/text_to_image) 

Multiple [AI 100 SoCs](../Architecture/index.md) with dedicated DDR memory, stacked on a accelerator card (SKUs) and/or on the server can be used to run very large models.

